# NLP
Sanskrit and Marathi translator using NLP Models -  
These model translates the under-resourced Languages like sanskrit and marathi to english. Where, we tried to build a sequence to sequence model using LSTM. The seq2seq models are the
best choice for solving complex problem related to NLP. To use the seq2seq model it is needed to build
an encoder-decoder architecture which both of them are also LSTM models. The encoder reads the input
seq and summarize it into a hidden layer of LSTM or something like vectors. The decoder is able to receive
this data and generate a sequence based on it.




